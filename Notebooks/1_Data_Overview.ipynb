{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10d3eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:02<00:00, 16.02it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.41it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# Load CSV files from local Data/raw directory\n",
    "train = pd.read_csv('../Data/raw/train.csv')\n",
    "test = pd.read_csv('../Data/raw/test.csv')\n",
    "sample = pd.read_csv('../Data/raw/sample_submission.csv')\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    # Đọc tệp Parquet\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    \n",
    "    # Tính toán các thống kê mô tả\n",
    "    desc_df = df.describe().T # .T để chuyển vị, đưa các cột thành chỉ mục và các thống kê thành cột\n",
    "    \n",
    "    # Tạo tên cột mới bằng cách kết hợp Tên cột gốc và Tên thống kê (ví dụ: 'Age_mean')\n",
    "    # Các thống kê mặc định: ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "    new_cols = []\n",
    "    values = []\n",
    "    \n",
    "    # Duyệt qua từng hàng (là từng cột gốc) của DataFrame thống kê\n",
    "    for col in desc_df.index:\n",
    "        for stat in desc_df.columns:\n",
    "            # Tạo tên mới: {Tên_cột_gốc}_{Tên_thống_kê}\n",
    "            new_name = f\"{col}_{stat}\"\n",
    "            new_cols.append(new_name)\n",
    "            \n",
    "            # Lấy giá trị thống kê tương ứng\n",
    "            values.append(desc_df.loc[col, stat])\n",
    "            \n",
    "    # Trả về các giá trị thống kê (dạng mảng 1D) và danh sách tên cột\n",
    "    # Đồng thời trả về ID\n",
    "    return values, new_cols, filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Sử dụng map như trước, kết quả sẽ là list các tuples: (values, new_cols, index)\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    # Tách kết quả thành 3 lists riêng biệt\n",
    "    stats_values, col_names_list, indexes = zip(*results)\n",
    "    \n",
    "    # Lấy danh sách tên cột từ mẫu đầu tiên (giả định tất cả các tệp có cùng cấu trúc cột)\n",
    "    if col_names_list:\n",
    "        new_columns = col_names_list[0]\n",
    "    else:\n",
    "        # Xử lý trường hợp không có tệp nào\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    # Tạo DataFrame mới sử dụng các giá trị thống kê và tên cột đã tạo\n",
    "    df = pd.DataFrame(list(stats_values), columns=new_columns)\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "\n",
    "# Load time series data from local Data/raw directory        \n",
    "train_ts = load_time_series(\"../Data/raw/series_train.parquet\")\n",
    "test_ts = load_time_series(\"../Data/raw/series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)   \n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a0940d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Basic_Demos-Enroll_Season',\n",
       " 'Basic_Demos-Age',\n",
       " 'Basic_Demos-Sex',\n",
       " 'CGAS-Season',\n",
       " 'CGAS-CGAS_Score',\n",
       " 'Physical-Season',\n",
       " 'Physical-BMI',\n",
       " 'Physical-Height',\n",
       " 'Physical-Weight',\n",
       " 'Physical-Waist_Circumference',\n",
       " 'Physical-Diastolic_BP',\n",
       " 'Physical-HeartRate',\n",
       " 'Physical-Systolic_BP',\n",
       " 'Fitness_Endurance-Season',\n",
       " 'Fitness_Endurance-Max_Stage',\n",
       " 'Fitness_Endurance-Time_Mins',\n",
       " 'Fitness_Endurance-Time_Sec',\n",
       " 'FGC-Season',\n",
       " 'FGC-FGC_CU',\n",
       " 'FGC-FGC_CU_Zone',\n",
       " 'FGC-FGC_GSND',\n",
       " 'FGC-FGC_GSND_Zone',\n",
       " 'FGC-FGC_GSD',\n",
       " 'FGC-FGC_GSD_Zone',\n",
       " 'FGC-FGC_PU',\n",
       " 'FGC-FGC_PU_Zone',\n",
       " 'FGC-FGC_SRL',\n",
       " 'FGC-FGC_SRL_Zone',\n",
       " 'FGC-FGC_SRR',\n",
       " 'FGC-FGC_SRR_Zone',\n",
       " 'FGC-FGC_TL',\n",
       " 'FGC-FGC_TL_Zone',\n",
       " 'BIA-Season',\n",
       " 'BIA-BIA_Activity_Level_num',\n",
       " 'BIA-BIA_BMC',\n",
       " 'BIA-BIA_BMI',\n",
       " 'BIA-BIA_BMR',\n",
       " 'BIA-BIA_DEE',\n",
       " 'BIA-BIA_ECW',\n",
       " 'BIA-BIA_FFM',\n",
       " 'BIA-BIA_FFMI',\n",
       " 'BIA-BIA_FMI',\n",
       " 'BIA-BIA_Fat',\n",
       " 'BIA-BIA_Frame_num',\n",
       " 'BIA-BIA_ICW',\n",
       " 'BIA-BIA_LDM',\n",
       " 'BIA-BIA_LST',\n",
       " 'BIA-BIA_SMM',\n",
       " 'BIA-BIA_TBW',\n",
       " 'PAQ_A-Season',\n",
       " 'PAQ_A-PAQ_A_Total',\n",
       " 'PAQ_C-Season',\n",
       " 'PAQ_C-PAQ_C_Total',\n",
       " 'SDS-Season',\n",
       " 'SDS-SDS_Total_Raw',\n",
       " 'SDS-SDS_Total_T',\n",
       " 'PreInt_EduHx-Season',\n",
       " 'PreInt_EduHx-computerinternet_hoursday',\n",
       " 'sii',\n",
       " 'X_count',\n",
       " 'X_mean',\n",
       " 'X_std',\n",
       " 'X_min',\n",
       " 'X_25%',\n",
       " 'X_50%',\n",
       " 'X_75%',\n",
       " 'X_max',\n",
       " 'Y_count',\n",
       " 'Y_mean',\n",
       " 'Y_std',\n",
       " 'Y_min',\n",
       " 'Y_25%',\n",
       " 'Y_50%',\n",
       " 'Y_75%',\n",
       " 'Y_max',\n",
       " 'Z_count',\n",
       " 'Z_mean',\n",
       " 'Z_std',\n",
       " 'Z_min',\n",
       " 'Z_25%',\n",
       " 'Z_50%',\n",
       " 'Z_75%',\n",
       " 'Z_max',\n",
       " 'enmo_count',\n",
       " 'enmo_mean',\n",
       " 'enmo_std',\n",
       " 'enmo_min',\n",
       " 'enmo_25%',\n",
       " 'enmo_50%',\n",
       " 'enmo_75%',\n",
       " 'enmo_max',\n",
       " 'anglez_count',\n",
       " 'anglez_mean',\n",
       " 'anglez_std',\n",
       " 'anglez_min',\n",
       " 'anglez_25%',\n",
       " 'anglez_50%',\n",
       " 'anglez_75%',\n",
       " 'anglez_max',\n",
       " 'non-wear_flag_count',\n",
       " 'non-wear_flag_mean',\n",
       " 'non-wear_flag_std',\n",
       " 'non-wear_flag_min',\n",
       " 'non-wear_flag_25%',\n",
       " 'non-wear_flag_50%',\n",
       " 'non-wear_flag_75%',\n",
       " 'non-wear_flag_max',\n",
       " 'light_count',\n",
       " 'light_mean',\n",
       " 'light_std',\n",
       " 'light_min',\n",
       " 'light_25%',\n",
       " 'light_50%',\n",
       " 'light_75%',\n",
       " 'light_max',\n",
       " 'battery_voltage_count',\n",
       " 'battery_voltage_mean',\n",
       " 'battery_voltage_std',\n",
       " 'battery_voltage_min',\n",
       " 'battery_voltage_25%',\n",
       " 'battery_voltage_50%',\n",
       " 'battery_voltage_75%',\n",
       " 'battery_voltage_max',\n",
       " 'time_of_day_count',\n",
       " 'time_of_day_mean',\n",
       " 'time_of_day_std',\n",
       " 'time_of_day_min',\n",
       " 'time_of_day_25%',\n",
       " 'time_of_day_50%',\n",
       " 'time_of_day_75%',\n",
       " 'time_of_day_max',\n",
       " 'weekday_count',\n",
       " 'weekday_mean',\n",
       " 'weekday_std',\n",
       " 'weekday_min',\n",
       " 'weekday_25%',\n",
       " 'weekday_50%',\n",
       " 'weekday_75%',\n",
       " 'weekday_max',\n",
       " 'quarter_count',\n",
       " 'quarter_mean',\n",
       " 'quarter_std',\n",
       " 'quarter_min',\n",
       " 'quarter_25%',\n",
       " 'quarter_50%',\n",
       " 'quarter_75%',\n",
       " 'quarter_max',\n",
       " 'relative_date_PCIAT_count',\n",
       " 'relative_date_PCIAT_mean',\n",
       " 'relative_date_PCIAT_std',\n",
       " 'relative_date_PCIAT_min',\n",
       " 'relative_date_PCIAT_25%',\n",
       " 'relative_date_PCIAT_50%',\n",
       " 'relative_date_PCIAT_75%',\n",
       " 'relative_date_PCIAT_max']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9929546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ENMO features from training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ENMO features:   0%|          | 0/996 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ENMO features: 100%|██████████| 996/996 [02:00<00:00,  8.28it/s]\n",
      "Extracting ENMO features: 100%|██████████| 996/996 [02:00<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ENMO features from test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ENMO features: 100%|██████████| 2/2 [00:00<00:00, 13.51it/s]\n",
      "Extracting ENMO features: 100%|██████████| 2/2 [00:00<00:00, 13.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract ENMO features (activity patterns) from time series data\n",
    "def extract_enmo(df_source, id=None):\n",
    "    \"\"\"\n",
    "    Extract activity patterns based on ENMO (Euclidean Norm Minus One) values\n",
    "    Categories: sedentary, light, moderate\n",
    "    \"\"\"\n",
    "    df = df_source.copy()\n",
    "    \n",
    "    # Filter out non-wear periods\n",
    "    df = df[df['non-wear_flag'] == 0]\n",
    "    df.drop('non-wear_flag', axis=1, inplace=True)\n",
    "    \n",
    "    # Classify activity types based on ENMO thresholds\n",
    "    df.loc[:, 'Type_activity'] = 'Non-assigned'\n",
    "    df.loc[(df['enmo'] < 10*1e-3), 'Type_activity'] = 'sedentary'\n",
    "    df.loc[(df['enmo'] >= 10*1e-3) & (df['enmo'] < 100*1e-3), 'Type_activity'] = 'light'\n",
    "    df.loc[(df['enmo'] >= 100*1e-3), 'Type_activity'] = 'moderate'\n",
    "    \n",
    "    # Calculate total wear time\n",
    "    total_wear = df['step'].count()\n",
    "    \n",
    "    # Calculate proportion of each activity type\n",
    "    if total_wear > 0:\n",
    "        sedentary_perall = df[df['Type_activity'] == 'sedentary']['step'].count() / total_wear\n",
    "        light_perall = df[df['Type_activity'] == 'light']['step'].count() / total_wear\n",
    "        moderate_perall = df[df['Type_activity'] == 'moderate']['step'].count() / total_wear\n",
    "    else:\n",
    "        sedentary_perall = light_perall = moderate_perall = 0\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'id': [id], \n",
    "        'sedentary_por': [sedentary_perall], \n",
    "        'light_por': [light_perall],\n",
    "        'moderate_por': [moderate_perall]\n",
    "    })\n",
    "\n",
    "def getEnmo(ts_path):\n",
    "    \"\"\"\n",
    "    Extract ENMO features from all time series files in a directory\n",
    "    \"\"\"\n",
    "    listdir = os.listdir(ts_path)\n",
    "    res_df = None\n",
    "    \n",
    "    for dir in tqdm(listdir, desc=\"Extracting ENMO features\"):\n",
    "        dft = pd.read_parquet(os.path.join(ts_path, dir, \"part-0.parquet\"))\n",
    "        \n",
    "        # Extract ID from directory name (format: id=xxxxx)\n",
    "        id = dir.split('=')[1] if '=' in dir else dir[3:]\n",
    "        ex_df = extract_enmo(dft, id=id)\n",
    "        \n",
    "        if res_df is None:\n",
    "            res_df = ex_df\n",
    "        else:\n",
    "            res_df = pd.concat([res_df, ex_df], ignore_index=True)\n",
    "    \n",
    "    return res_df\n",
    "\n",
    "# Extract ENMO features from train and test time series\n",
    "print(\"Extracting ENMO features from training data...\")\n",
    "train_enmo = getEnmo(\"../Data/raw/series_train.parquet\")\n",
    "\n",
    "print(\"\\nExtracting ENMO features from test data...\")\n",
    "test_enmo = getEnmo(\"../Data/raw/series_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "827dca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Dataset đã được ghép thành công!\n",
      "  - Train shape: (2736, 181)\n",
      "  - Test shape: (20, 158)\n",
      "  - Columns: ['id', 'Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex', 'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI', 'Physical-Height', 'Physical-Weight']... (showing first 10)\n",
      "\n",
      "Features included:\n",
      "  - Original features: 155\n",
      "  - Time series features: 96\n",
      "  - ENMO features: 3 (sedentary_por, light_por, moderate_por)\n",
      "  - Total: 181 columns\n"
     ]
    }
   ],
   "source": [
    "# Reload the original train and test data with IDs for merging\n",
    "train_with_id = pd.read_csv('../Data/raw/train.csv')\n",
    "test_with_id = pd.read_csv('../Data/raw/test.csv')\n",
    "\n",
    "# Merge ENMO features with train and test data\n",
    "train_with_id = pd.merge(train_with_id, train_enmo, how=\"left\", on='id')\n",
    "test_with_id = pd.merge(test_with_id, test_enmo, how=\"left\", on='id')\n",
    "\n",
    "# Merge with existing time series features\n",
    "train_with_id = pd.merge(train_with_id, train_ts, how=\"left\", on='id')\n",
    "test_with_id = pd.merge(test_with_id, test_ts, how=\"left\", on='id')\n",
    "\n",
    "# Merge all features together (no preprocessing, just merging)\n",
    "train_final = train_with_id.copy()\n",
    "test_final = test_with_id.copy()\n",
    "\n",
    "train_final = train_final.dropna(subset='sii')\n",
    "\n",
    "print(f\"\\n✓ Dataset đã được ghép thành công!\")\n",
    "print(f\"  - Train shape: {train_final.shape}\")\n",
    "print(f\"  - Test shape: {test_final.shape}\")\n",
    "print(f\"  - Columns: {train_final.columns.tolist()[:10]}... (showing first 10)\")\n",
    "print(f\"\\nFeatures included:\")\n",
    "print(f\"  - Original features: {len(train.columns)}\")\n",
    "print(f\"  - Time series features: {len(time_series_cols)}\")\n",
    "print(f\"  - ENMO features: 3 (sedentary_por, light_por, moderate_por)\")\n",
    "print(f\"  - Total: {train_final.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b020ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dữ liệu đã được lưu thành công!\n",
      "  - train_processed.csv: (2736, 181)\n",
      "  - test_processed.csv: (20, 158)\n",
      "  - train_ts_features.csv: (996, 97)\n",
      "  - test_ts_features.csv: (2, 97)\n",
      "  - train_enmo_features.csv: (996, 4)\n",
      "  - test_enmo_features.csv: (2, 4)\n",
      "  - sample_submission.csv: (20, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create processed directory if it doesn't exist\n",
    "os.makedirs('../Data/processed', exist_ok=True)\n",
    "\n",
    "# Save processed train and test data (with ENMO features)\n",
    "train_final.to_csv('../Data/processed/train_processed.csv', index=False)\n",
    "test_final.to_csv('../Data/processed/test_processed.csv', index=False)\n",
    "\n",
    "# Save sample submission (for reference)\n",
    "sample.to_csv('../Data/processed/sample_submission.csv', index=False)\n",
    "\n",
    "print(\"✓ Dữ liệu đã được lưu thành công!\")\n",
    "print(f\"  - train_processed.csv: {train_final.shape}\")\n",
    "print(f\"  - test_processed.csv: {test_final.shape}\")\n",
    "print(f\"  - train_ts_features.csv: {train_ts.shape}\")\n",
    "print(f\"  - test_ts_features.csv: {test_ts.shape}\")\n",
    "print(f\"  - train_enmo_features.csv: {train_enmo.shape}\")\n",
    "print(f\"  - test_enmo_features.csv: {test_enmo.shape}\")\n",
    "print(f\"  - sample_submission.csv: {sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aade6380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   step         X         Y         Z      enmo     anglez  non-wear_flag  \\\n",
      "0     0 -0.075242 -0.256743 -0.973791  0.038081 -72.952141            0.0   \n",
      "1     1 -0.265893 -0.270508 -0.765470  0.077430 -52.849220            0.0   \n",
      "2     2  0.334517 -0.548602 -0.588596  0.039162 -44.118084            0.0   \n",
      "3     3  0.000193 -0.021069 -0.999681  0.001450 -88.759613            0.0   \n",
      "4     4 -0.000685 -0.020681 -0.997677  0.000491 -88.756958            0.0   \n",
      "\n",
      "   light  battery_voltage     time_of_day  weekday  quarter  \\\n",
      "0    5.0      4202.000000  51250000000000        2        4   \n",
      "1    0.5      4185.333496  51255000000000        2        4   \n",
      "2   11.5      4185.500000  51260000000000        2        4   \n",
      "3    0.0      4185.666504  51265000000000        2        4   \n",
      "4    8.5      4185.833496  51270000000000        2        4   \n",
      "\n",
      "   relative_date_PCIAT  \n",
      "0                 -9.0  \n",
      "1                 -9.0  \n",
      "2                 -9.0  \n",
      "3                 -9.0  \n",
      "4                 -9.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213423 entries, 0 to 213422\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   step                 213423 non-null  uint32 \n",
      " 1   X                    213423 non-null  float32\n",
      " 2   Y                    213423 non-null  float32\n",
      " 3   Z                    213423 non-null  float32\n",
      " 4   enmo                 213423 non-null  float32\n",
      " 5   anglez               213423 non-null  float32\n",
      " 6   non-wear_flag        213423 non-null  float32\n",
      " 7   light                213423 non-null  float32\n",
      " 8   battery_voltage      213423 non-null  float32\n",
      " 9   time_of_day          213423 non-null  int64  \n",
      " 10  weekday              213423 non-null  int8   \n",
      " 11  quarter              213423 non-null  int8   \n",
      " 12  relative_date_PCIAT  213423 non-null  float32\n",
      "dtypes: float32(9), int64(1), int8(2), uint32(1)\n",
      "memory usage: 10.2 MB\n",
      "None\n",
      "Index(['step', 'X', 'Y', 'Z', 'enmo', 'anglez', 'non-wear_flag', 'light',\n",
      "       'battery_voltage', 'time_of_day', 'weekday', 'quarter',\n",
      "       'relative_date_PCIAT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file Parquet\n",
    "df = pd.read_parquet(\"../Data/raw/series_train.parquet/id=0a418b57/part-0.parquet\")\n",
    "\n",
    "# Hiển thị thông tin về dữ liệu trong Parquet\n",
    "print(df.head())  # Xem 5 dòng đầu tiên của dữ liệu\n",
    "print(df.info())  # Thông tin chi tiết về cấu trúc DataFrame (số lượng các cột, kiểu dữ liệu, v.v.)\n",
    "print(df.columns)  # Hiển thị tên các cột trong DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
